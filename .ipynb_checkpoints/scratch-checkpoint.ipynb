{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Copyright 2019-2020 Darien Schettler (https://github.com/darien-schettler)\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "    http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "\"\"\"\n",
    "\n",
    "class ResizeLike(tf.keras.layers.Layer):\n",
    "    \"\"\" Keras layer to resize a tensor to the reference tensor shape.\n",
    "\n",
    "    Attributes:\n",
    "        keras.layers.Layer: Base layer class.\n",
    "            This is the class from which all layers inherit.\n",
    "                -   A layer is a class implementing common neural networks\n",
    "                    operations, such as convolution, batch norm, etc.\n",
    "                -   These operations require managing weights,\n",
    "                    losses, updates, and inter-layer connectivity.\n",
    "    \"\"\"\n",
    "\n",
    "    def call(self, inputs, ref, **kwargs):\n",
    "        \"\"\"TODO: docstring\n",
    "\n",
    "        Args:\n",
    "            inputs (TODO): TODO\n",
    "            ref (TODO): TODO\n",
    "\n",
    "        **kwargs:\n",
    "            TODO\n",
    "\n",
    "        Returns:\n",
    "            TODO\n",
    "        \"\"\"\n",
    "\n",
    "        image, boxes = inputs\n",
    "        shape = tf.cast(tf.shape(image), tf.keras.backend.floatx())\n",
    "\n",
    "        if tf.keras.backend.image_data_format() == 'channels_first':\n",
    "            _, _, height, width = tf.unstack(value=shape, axis=0)\n",
    "        else:\n",
    "            _, height, width, _ = tf.unstack(value=shape, axis=0)\n",
    "\n",
    "        x1, y1, x2, y2 = tf.unstack(value=boxes, axis=-1)\n",
    "        x1 = tf.clip_by_value(x1, clip_value_min=0, clip_value_max=width)\n",
    "        y1 = tf.clip_by_value(y1, clip_value_min=0, clip_value_max=height)\n",
    "        x2 = tf.clip_by_value(x2, clip_value_min=0, clip_value_max=width)\n",
    "        y2 = tf.clip_by_value(y2, clip_value_min=0, clip_value_max=height)\n",
    "\n",
    "        return tf.stack(values=[x1, y1, x2, y2], axis=2)\n",
    "\n",
    "    \n",
    "    def compute_output_shape(self, ref):\n",
    "        \"\"\"TODO: docstring\n",
    "\n",
    "        Args:\n",
    "            input_shape (TODO): TODO\n",
    "\n",
    "        Returns:\n",
    "            TODO\n",
    "        \"\"\"\n",
    "        return ref.shape\n",
    "        \n",
    "    def resize_like(input_tensor, ref_tensor):\n",
    "    \"\"\" Resize an image tensor to the same size/shape as a reference image tensor\n",
    "\n",
    "    Args:\n",
    "        input_tensor: (image tensor) Input image tensor that will be resized\n",
    "        ref_tensor: (image tensor) Reference image tensor that we want to resize the input tensor to.\n",
    "\n",
    "    Returns:\n",
    "        reshaped tensor\n",
    "    \"\"\"\n",
    "    reshaped_tensor = tf.image.resize(images=input_tensor,\n",
    "                                      size=tf.shape(ref_tensor)[1:3],\n",
    "                                      method=tf.image.ResizeMethod.NEAREST_NEIGHBOR,\n",
    "                                      preserve_aspect_ratio=False,\n",
    "                                      antialias=False)\n",
    "    return reshaped_tensor\n",
    "\n",
    "    # TODO: Understanding\n",
    "    def get_config(self):\n",
    "        \"\"\"TODO: docstring\n",
    "\n",
    "        Returns:\n",
    "            TODO\n",
    "        \"\"\"\n",
    "\n",
    "        config = super(GenerateAnchors, self).get_config()\n",
    "        config.update({\n",
    "            'size': self.size,\n",
    "            'stride': self.stride,\n",
    "            'ratios': self.ratios.tolist(),\n",
    "            'scales': self.scales.tolist(),\n",
    "        })\n",
    "\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input_1 = tf.keras.layers.Input(shape=(160,160,3))\n",
    "model_input_2 = tf.keras.layers.Input(shape=(160,160,3))\n",
    "\n",
    "model_output_1 = tf.keras.layers.Conv2D(filters=64, \n",
    "                                        kernel_size=(1, 1), \n",
    "                                        use_bias=False,\n",
    "                                        kernel_initializer='he_normal',\n",
    "                                        name='conv_name_base')(model_input_1)\n",
    "\n",
    "model_output_2 = tf.keras.layers.Lambda(function=resize_like,\n",
    "                                        arguments={'ref_tensor': tf.identity(model_output_1)})(model_input_2)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[model_input_1, model_input_2],\n",
    "                                      outputs=[model_output_1, model_output_2],\n",
    "                                      name=\"test_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = [np.ones((1,160,160,3)), np.zeros((1,160,160,3))]\n",
    "\n",
    "model.predict(x=dummy_input, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T21:42:13.204807Z",
     "start_time": "2020-03-03T21:42:08.687872Z"
    }
   },
   "outputs": [],
   "source": [
    "!export AUTOGRAPH_VERBOSITY=10\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from bar_cnn.models.detectors import retinanet\n",
    "from bar_cnn.models.backbones import resnet\n",
    "\n",
    "# Local Imports\n",
    "from bar_cnn import custom\n",
    "from bar_cnn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T21:42:15.650964Z",
     "start_time": "2020-03-03T21:42:13.211626Z"
    }
   },
   "outputs": [],
   "source": [
    "resnet_backbone = resnet.ResNetBoxAttnBackbone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T21:42:15.659055Z",
     "start_time": "2020-03-03T21:42:15.654200Z"
    }
   },
   "outputs": [],
   "source": [
    "backbone_layers = resnet_backbone.model.outputs[1:]\n",
    "inputs = resnet_backbone.model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T21:42:19.401790Z",
     "start_time": "2020-03-03T21:42:15.662583Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "barcnn = retinanet.RetinaNet(input_tensors=inputs, backbone_layers=backbone_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T21:43:40.782588Z",
     "start_time": "2020-03-03T21:43:40.772574Z"
    }
   },
   "outputs": [],
   "source": [
    "for k,v in barcnn.__dict__.items():\n",
    "    print(\"Key:\\t{}\".format(k))\n",
    "    print(\"Value:\\t{}\\n\".format(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-03T21:48:27.650161Z",
     "start_time": "2020-03-03T21:48:27.567382Z"
    }
   },
   "outputs": [],
   "source": [
    "print(barcnn.model.summary())\n",
    "print(\"\\n\\nOUTPUT LAYERS\")\n",
    "for output in barcnn.model.outputs: print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_input=np.zeros((160,160,3), dtype=np.uint8)\n",
    "mask_input[10:70, 10:70, :] = np.ones((60,60,3), dtype=np.uint8)*255\n",
    "plt.imshow(mask_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image_input=cv2.resize(cv2.cvtColor(cv2.imread(\"./tests/data/test_1.jpg\"),cv2.COLOR_BGR2RGB), (160,160))\n",
    "plt.imshow(image_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_image_input = np.expand_dims(image_input, axis=0)\n",
    "batched_mask_input = np.expand_dims(mask_input, axis=0)\n",
    "\n",
    "print(\"Image Input : {}\".format(batched_image_input.shape))\n",
    "print(\"Mask Input : {}\".format(batched_mask_input.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcnn.model.predict(x=[batched_image_input, batched_mask_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = [batched_image_input, batched_mask_input]\n",
    "resnet_backbone.model.predict(x=test_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TROUBLESHOOTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define The First Part of the ResNET Model Up to the Error\n",
    "\n",
    "### Define variables and remove self.\n",
    "### Functions First Then Line By Line Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bn_axis():\n",
    "    \"\"\" Defines the batch normalization axis\"\"\"\n",
    "    if tf.keras.backend.image_data_format() == 'channels_last':\n",
    "        return 3\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def get_layer_name(prefix, stage, block):\n",
    "    \"\"\" Get layer name built from prefix, stage, and block number\n",
    "\n",
    "    Args:\n",
    "        prefix (string): TODO\n",
    "        stage (string): TODO\n",
    "        block (string): TODO\n",
    "\n",
    "    Returns:\n",
    "        Layer name as a string\n",
    "    \"\"\"\n",
    "    return \"{}{}{}_branch\".format(str(prefix), str(stage), str(block))\n",
    "\n",
    "\n",
    "image_size=160\n",
    "regular_kernel_initializer='he_normal'\n",
    "attention_kernel_initializer='zeros'\n",
    "activation_function='relu'\n",
    "last_pool=None\n",
    "utilize_bias=False\n",
    "padding_style=\"same\"\n",
    "freeze_batch_norm=True\n",
    "model_name=\"resnet-bar-cnn\"\n",
    "\n",
    "image_shape = (image_size, image_size, 3)\n",
    "bn_axis = get_bn_axis()\n",
    "reg_kernel_init = regular_kernel_initializer\n",
    "attn_kernel_init = attention_kernel_initializer\n",
    "activation_fn = activation_function\n",
    "last_pool_style = last_pool\n",
    "use_bias = utilize_bias\n",
    "pad_style = padding_style\n",
    "freeze_bn = freeze_batch_norm\n",
    "    \n",
    "def identity_block(input_tensor,\n",
    "                   kernel_size,\n",
    "                   filters,\n",
    "                   stage,\n",
    "                   block,\n",
    "                   attn_map=None):\n",
    "    \"\"\"The identity block is the block that has no convolutional layer at shortcut.\n",
    "\n",
    "    Args:\n",
    "        input_tensor (Tensor): TODO\n",
    "        kernel_size (int): the kernel size of middle conv layer at main path\n",
    "        filters (list of ints): the filters of 3 conv layer at main path\n",
    "        stage (int): current stage label, used for generating layer names\n",
    "        block (str): 'a','b'..., current block label, used for generating layer names\n",
    "        attn_map (TODO, optional): TODO (defaults to None)\n",
    "\n",
    "    Returns:\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "\n",
    "    # map filter size to filers1, filters2, and filters3\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    # Names take the form \"<prefix><stage><block>_branch\"\n",
    "    conv_name_base = get_layer_name(prefix=\"res\", stage=stage, block=block)\n",
    "    bn_name_base = get_layer_name(prefix=\"bn\", stage=stage, block=block)\n",
    "    attn_map_name_base = get_layer_name(prefix=\"attn\", stage=stage, block=block)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(filters=filters1, kernel_size=(1, 1), use_bias=use_bias,\n",
    "                               kernel_initializer=reg_kernel_init,\n",
    "                               name=conv_name_base + '2a')(input_tensor)\n",
    "\n",
    "    x = custom.layers.BatchNormalization(freeze=freeze_bn, axis=bn_axis,\n",
    "                                         name=bn_name_base + '2a')(x)\n",
    "    x = tf.keras.layers.Activation(activation_fn)(x)\n",
    "\n",
    "    # This is the convolutional layer that we want to modify.\n",
    "    x = tf.keras.layers.Conv2D(filters=filters2, kernel_size=kernel_size,\n",
    "                               padding=pad_style, use_bias=use_bias,\n",
    "                               kernel_initializer=reg_kernel_init,\n",
    "                               name=conv_name_base + '2b')(x)\n",
    "\n",
    "    # Get the output shape of the layer\n",
    "    attn_map_shaped = tf.keras.layers.Lambda(function=utils.tf.resize_like,\n",
    "                                             arguments={'ref_tensor': x})(attn_map)\n",
    "    # Get the number of filters required\n",
    "    num_attn_filters = x.shape[3]\n",
    "\n",
    "    x = custom.layers.BatchNormalization(freeze=freeze_bn, axis=bn_axis,\n",
    "                                         name=bn_name_base + '2b')(x)\n",
    "\n",
    "    # Do a 3x3 convolution on the attention map\n",
    "    attention_layer = tf.keras.layers.Conv2D(filters=num_attn_filters, kernel_size=3,\n",
    "                                             padding=pad_style, use_bias=use_bias,\n",
    "                                             kernel_initializer=attn_kernel_init,\n",
    "                                             name=attn_map_name_base + '2b')(attn_map_shaped)\n",
    "    x = tf.keras.layers.add(inputs=[x, attention_layer])\n",
    "    x = tf.keras.layers.Activation(activation_fn)(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(filters=filters3,\n",
    "                               kernel_size=(1, 1),\n",
    "                               use_bias=use_bias,\n",
    "                               kernel_initializer=reg_kernel_init,\n",
    "                               name=conv_name_base + '2c')(x)\n",
    "\n",
    "    x = custom.layers.BatchNormalization(freeze=freeze_bn,\n",
    "                                         axis=bn_axis,\n",
    "                                         name=bn_name_base + '2c')(x)\n",
    "    x = tf.keras.layers.add(inputs=[x, input_tensor])\n",
    "    x = tf.keras.layers.Activation(activation_fn)(x)\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor,\n",
    "               kernel_size,\n",
    "               filters,\n",
    "               stage,\n",
    "               block,\n",
    "               strides=(2, 2),\n",
    "               attn_map=None):\n",
    "    \"\"\"A block that has a conv layer at shortcut.\n",
    "\n",
    "    Args:\n",
    "        input_tensor: (TODO) input tensor\n",
    "        kernel_size: (TODO) default 3, the kernel size of middle conv layer at main path\n",
    "        filters: (TODO) list of integers, the filters of 3 conv layer at main path\n",
    "        stage: (TODO) integer, current stage label, used for generating layer names\n",
    "        block: (TODO) 'a','b'..., current block label, used for generating layer names\n",
    "        strides: (TODO, optional) Strides for the first conv layer in the block. (defaults to (2,2))\n",
    "        attn_map: (TODO, optional) TODO (defaults to None)\n",
    "\n",
    "    Returns:\n",
    "        Output tensor for the block.\n",
    "\n",
    "    Note that from stage 3, the first conv layer at main path is with strides=(2, 2)\n",
    "    Note that the shortcut should have strides=(2, 2)\n",
    "    \"\"\"\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    # Names take the form \"<prefix><stage><block>_branch\"\n",
    "    conv_name_base = get_layer_name(prefix=\"res\", stage=stage, block=block)\n",
    "    bn_name_base = get_layer_name(prefix=\"bn\", stage=stage, block=block)\n",
    "    attn_map_name_base = get_layer_name(prefix=\"attn\", stage=stage, block=block)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(filters=filters1, kernel_size=(1, 1),\n",
    "                               strides=strides, use_bias=use_bias,\n",
    "                               kernel_initializer=reg_kernel_init,\n",
    "                               name=conv_name_base + '2a')(input_tensor)\n",
    "\n",
    "    x = custom.layers.BatchNormalization(freeze=freeze_bn, axis=bn_axis,\n",
    "                                         name=bn_name_base + '2a')(x)\n",
    "    x = tf.keras.layers.Activation(activation_fn)(x)\n",
    "\n",
    "    # This is the convolutional layer that we want to modify.\n",
    "    x = tf.keras.layers.Conv2D(filters=filters2, kernel_size=kernel_size,\n",
    "                               padding=pad_style, use_bias=use_bias,\n",
    "                               kernel_initializer=reg_kernel_init,\n",
    "                               name=conv_name_base + '2b')(x)\n",
    "\n",
    "    # Get the output shape of the layer\n",
    "    attn_map_shaped = tf.keras.layers.Lambda(function=utils.tf.resize_like,\n",
    "                                             arguments={'ref_tensor': x})(attn_map)\n",
    "    # Get the number of filters required\n",
    "    num_attn_filters = x.shape[3]\n",
    "\n",
    "    x = custom.layers.BatchNormalization(freeze=freeze_bn, axis=bn_axis,\n",
    "                                         name=bn_name_base + '2b')(x)\n",
    "\n",
    "    # Do a 3x3 convolution on the attention map\n",
    "    attention_layer = tf.keras.layers.Conv2D(filters=num_attn_filters, kernel_size=3,\n",
    "                                             padding=pad_style, use_bias=use_bias,\n",
    "                                             kernel_initializer=attn_kernel_init,\n",
    "                                             name=attn_map_name_base + '2b')(attn_map_shaped)\n",
    "\n",
    "    x = tf.keras.layers.add(inputs=[x, attention_layer])\n",
    "    x = tf.keras.layers.Activation(activation_fn)(x)\n",
    "    \n",
    "    x = tf.keras.layers.Conv2D(filters=filters3, kernel_size=(1, 1), use_bias=use_bias,\n",
    "                               kernel_initializer=reg_kernel_init,\n",
    "                               name=conv_name_base + '2c')(x)\n",
    "\n",
    "    x = custom.layers.BatchNormalization(freeze=freeze_bn, axis=bn_axis,\n",
    "                                         name=bn_name_base + '2c')(x)\n",
    "\n",
    "    shortcut = tf.keras.layers.Conv2D(filters=filters3, kernel_size=(1, 1),\n",
    "                                      strides=strides, use_bias=use_bias,\n",
    "                                      kernel_initializer=reg_kernel_init,\n",
    "                                      name=conv_name_base + '1')(input_tensor)\n",
    "\n",
    "    shortcut = custom.layers.BatchNormalization(freeze=freeze_bn, axis=bn_axis,\n",
    "                                                name=bn_name_base + '1')(shortcut)\n",
    "\n",
    "    x = tf.keras.layers.add(inputs=[x, shortcut])\n",
    "    x = tf.keras.layers.Activation(activation_fn)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = tf.keras.layers.Input(shape=image_shape)\n",
    "attn_map_input = tf.keras.layers.Input(shape=image_shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = tf.keras.layers.Input(shape=image_shape)\n",
    "attn_map_input = tf.keras.layers.Input(shape=image_shape)\n",
    "\n",
    "attn_map_shaped = tf.keras.layers.Lambda(function=utils.tf.resize_like,\n",
    "                                         arguments={'ref_tensor': x})(attn_map)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[img_input, attn_map_input],\n",
    "                                      outputs=attn_map_shaped,\n",
    "                                      name=model_name)\n",
    "\n",
    "\n",
    "\n",
    "# # ################################################################## #\n",
    "# #                     BUILD STAGE 1 (INPUT) BLOCK                    #\n",
    "# # ################################################################## #\n",
    "# x = tf.keras.layers.Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2),\n",
    "#                            padding=pad_style, use_bias=use_bias,\n",
    "#                            kernel_initializer=reg_kernel_init,\n",
    "#                            name='conv1')(img_input)\n",
    "\n",
    "# x = custom.layers.BatchNormalization(freeze=freeze_bn, axis=bn_axis,\n",
    "#                                      name='bn_conv1')(x)\n",
    "# x = tf.keras.layers.Activation(activation_fn)(x)\n",
    "# x = tf.keras.layers.ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n",
    "# x = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
    "\n",
    "# # ################################################################## #\n",
    "# # ################################################################## #\n",
    "# # ################################################################## #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The problem is currently within the conv_block so we will dissect it line by line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################################################## #\n",
    "#                            CONV BLOCK                              #\n",
    "# ################################################################## #\n",
    "# Defined in fn call\n",
    "input_tensor=x\n",
    "kernel_size=3\n",
    "filters=[64, 64, 256]\n",
    "stage=2\n",
    "block='a'\n",
    "strides=(1, 1)\n",
    "attn_map=attn_map_input\n",
    "\n",
    "filters1, filters2, filters3 = filters\n",
    "\n",
    "# Names take the form \"<prefix><stage><block>_branch\"\n",
    "conv_name_base = get_layer_name(prefix=\"res\", stage=stage, block=block)\n",
    "bn_name_base = get_layer_name(prefix=\"bn\", stage=stage, block=block)\n",
    "attn_map_name_base = get_layer_name(prefix=\"attn\", stage=stage, block=block)\n",
    "\n",
    "x = tf.keras.layers.Conv2D(filters=filters1, kernel_size=(1, 1),\n",
    "                           strides=strides, use_bias=use_bias,\n",
    "                           kernel_initializer=reg_kernel_init,\n",
    "                           name=conv_name_base + '2a')(input_tensor)\n",
    "\n",
    "x = custom.layers.BatchNormalization(freeze=freeze_bn, axis=bn_axis,\n",
    "                                         name=bn_name_base + '2a')(x)\n",
    "x = tf.keras.layers.Activation(activation_fn)(x)\n",
    "\n",
    "# This is the convolutional layer that we want to modify.\n",
    "x = tf.keras.layers.Conv2D(filters=filters2, kernel_size=kernel_size,\n",
    "                           padding=pad_style, use_bias=use_bias,\n",
    "                           kernel_initializer=reg_kernel_init,\n",
    "                           name=conv_name_base + '2b')(x)\n",
    "\n",
    "# ################################################################## #\n",
    "# ################################################################## #\n",
    "# ################################################################## #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We know the problem stems from this fn/line so we dissect it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def resize_like(input_tensor, ref_tensor):\n",
    "    \"\"\" Resize an image tensor to the same size/shape as a reference image tensor\n",
    "\n",
    "    Args:\n",
    "        input_tensor: (image tensor) Input image tensor that will be resized\n",
    "        ref_tensor: (image tensor) Reference image tensor that we want to resize the input tensor to.\n",
    "\n",
    "    Returns:\n",
    "        reshaped tensor\n",
    "    \"\"\"\n",
    "    reshaped_tensor = tf.image.resize(images=input_tensor,\n",
    "                                      size=tf.shape(ref_tensor)[1:3],\n",
    "                                      method=tf.image.ResizeMethod.NEAREST_NEIGHBOR,\n",
    "                                      preserve_aspect_ratio=False,\n",
    "                                      antialias=False,\n",
    "                                      name=None)\n",
    "    return reshaped_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_like = tf.convert_to_tensor(np.ones((1, 40,40,64)))\n",
    "trans_me = tf.convert_to_tensor(np.expand_dims(image_input, axis=0))\n",
    "\n",
    "print(is_like.shape)\n",
    "print(trans_me.shape)\n",
    "\n",
    "resized = resize_like(trans_me, is_like)\n",
    "print(resized.shape)\n",
    "print(type(is_like))\n",
    "print(type(resized))\n",
    "\n",
    "plt.imshow(trans_me.numpy()[0, :, :, :])\n",
    "plt.show()\n",
    "plt.imshow(resized.numpy()[0, :, :, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the output shape of the layer\n",
    "attn_map_shaped = tf.keras.layers.Lambda(function=resize_like,\n",
    "                                         arguments={'ref_tensor': x})(attn_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################################################################## #\n",
    "#                        BUILD STAGE 2 BLOCK                         #\n",
    "# ################################################################## #\n",
    "# x = conv_block(input_tensor=x, kernel_size=3, filters=[64, 64, 256],\n",
    "#                stage=2, block='a', strides=(1, 1), attn_map=attn_map_input)\n",
    "\n",
    "#     x = self.identity_block(input_tensor=x, kernel_size=3, filters=[64, 64, 256],\n",
    "#                             stage=2, block='b', attn_map=attn_map_input)\n",
    "#     x = self.identity_block(input_tensor=x, kernel_size=3, filters=[64, 64, 256],\n",
    "#                             stage=2, block='c', attn_map=attn_map_input)\n",
    "#     self.stage_outputs.append(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[img_input, attn_map_input],\n",
    "                                      outputs=attn_map_shaped,\n",
    "                                      name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x=test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.Model(inputs=[img_input, attn_map_input],\n",
    "#                                       outputs=self.stage_outputs,\n",
    "#                                       name=self.model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
